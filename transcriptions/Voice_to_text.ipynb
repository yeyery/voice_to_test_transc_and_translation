{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24c0601-6f5a-4c85-a0aa-a011cd03036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\NSCC\\Capstone\\voice_to_test_transc_and_translation\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting offline transcription and translation... Press Ctrl+C to stop.\n",
      "(English): He was an overdrive with that kind of hype. Even the f-horn, that's attempt out here. We can't talk a little bit about\n",
      "(French): C'était un overdrive avec ce genre de hype. Même le f-horn, c'est une tentative ici.\n",
      "(English): dope.\n",
      "(French): Dope.\n",
      "(English): Hello.\n",
      "(French): Bonjour.\n",
      "(English): How are you?\n",
      "(French): Comment allez-vous ?\n",
      "(English): Good, thank you.\n",
      "(French): Bien, merci.\n",
      "(English): Thanks.\n",
      "(French): C'est gentil.\n",
      "(English): Thanks for watching.\n",
      "(French): Merci d'avoir regardé.\n",
      "\n",
      "Transcription stopped.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load the Whisper model for speech-to-text\n",
    "whisper_model = whisper.load_model(\"tiny\")  # Use \"small\", \"medium\", or \"large\" for better accuracy\n",
    "\n",
    "# Load MarianMT for English-to-French translation\n",
    "marian_model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(marian_model_name)\n",
    "translator_model = MarianMTModel.from_pretrained(marian_model_name)\n",
    "\n",
    "# Queue to hold audio chunks\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Function to capture audio in real-time\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    audio_queue.put(indata.copy())\n",
    "\n",
    "# Function to translate text offline\n",
    "def translate_to_french(english_text):\n",
    "    english_text = english_text.strip()  # Remove extra spaces\n",
    "    if english_text:  # Only process non-empty text\n",
    "        tokenized_text = tokenizer(english_text, return_tensors=\"pt\", padding=True)\n",
    "        translated_tokens = translator_model.generate(**tokenized_text)\n",
    "        french_translation = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "        return french_translation\n",
    "    return \"No translation available\"\n",
    "\n",
    "# Function to transcribe and translate audio continuously\n",
    "def continuous_transcription_and_translation():\n",
    "    print(\"Starting offline transcription and translation... Press Ctrl+C to stop.\")\n",
    "\n",
    "    samplerate = 16000  # Required sampling rate for Whisper\n",
    "    max_buffer_size = samplerate * 10  # Limit buffer size to 10 seconds\n",
    "\n",
    "    with sd.InputStream(callback=audio_callback, channels=1, samplerate=samplerate, dtype=\"float32\"):\n",
    "        audio_buffer = np.zeros((0,), dtype=\"float32\")  # Initialize an empty audio buffer\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                # Collect audio from the queue\n",
    "                while not audio_queue.empty():\n",
    "                    audio_chunk = audio_queue.get()\n",
    "                    audio_buffer = np.concatenate((audio_buffer, audio_chunk.flatten()))\n",
    "\n",
    "                # Trim buffer if it exceeds max size\n",
    "                if len(audio_buffer) > max_buffer_size:\n",
    "                    audio_buffer = audio_buffer[-max_buffer_size:]\n",
    "\n",
    "                # Process audio in ~3-second chunks\n",
    "                if len(audio_buffer) >= samplerate * 3:\n",
    "                    audio_data = audio_buffer[:samplerate * 3]\n",
    "                    audio_buffer = audio_buffer[samplerate * 3:]\n",
    "\n",
    "                    # Normalize and transcribe audio\n",
    "                    audio_data = np.clip(audio_data, -1.0, 1.0)\n",
    "                    result = whisper_model.transcribe(audio_data, language=\"en\", task=\"transcribe\", fp16=False)\n",
    "                    english_text = result.get(\"text\", \"\").strip()\n",
    "\n",
    "                    if english_text:\n",
    "                        print(\"(English):\", english_text)\n",
    "\n",
    "                        # Translate to French\n",
    "                        french_translation = translate_to_french(english_text)\n",
    "                        print(\"(French):\", french_translation)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTranscription stopped.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the transcription and translation\n",
    "continuous_transcription_and_translation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9f902-bb65-42a1-8814-857a2cac2021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
